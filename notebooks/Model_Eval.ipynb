{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import the pipeline class to reuse feature engineering logic\n",
    "# We add 'src' to path to ensure we can import it regardless of where this script is run\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'src')))\n",
    "try:\n",
    "    from src.csat_pipelining import CSATPredictor\n",
    "except ImportError:\n",
    "    # Fallback: try importing if we are already in root\n",
    "    from src.csat_pipelining import CSATPredictor\n",
    "\n",
    "def evaluate_model():\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(\"      DeepCSAT Model Evaluation\")\n",
    "    print(\"------------------------------------------------\")\n",
    "\n",
    "    # 1. Robust Path Finding\n",
    "    # This logic searches for files whether you run from root, src, or notebooks folder\n",
    "    filename = \"eCommerce_Customer_support_data.csv\"\n",
    "    model_name = \"csat_model.pkl\"\n",
    "    \n",
    "    # Places to look for the 'data' and 'models' folders\n",
    "    search_roots = [\n",
    "        os.getcwd(),                                  # Current CLI location\n",
    "        os.path.dirname(os.path.abspath(__file__)),   # Script location\n",
    "        os.path.dirname(os.path.dirname(os.path.abspath(__file__))) # Parent of script\n",
    "    ]\n",
    "    \n",
    "    DATA_PATH = None\n",
    "    MODEL_PATH = None\n",
    "    \n",
    "    for root in search_roots:\n",
    "        # Check for data\n",
    "        possible_data = os.path.join(root, \"data\", filename)\n",
    "        if os.path.exists(possible_data):\n",
    "            DATA_PATH = possible_data\n",
    "            \n",
    "        # Check for model\n",
    "        possible_model = os.path.join(root, \"models\", model_name)\n",
    "        if os.path.exists(possible_model):\n",
    "            MODEL_PATH = possible_model\n",
    "            \n",
    "    # Set defaults for error printing if still not found\n",
    "    if DATA_PATH is None: DATA_PATH = os.path.join(\"data\", filename)\n",
    "    if MODEL_PATH is None: MODEL_PATH = os.path.join(\"models\", model_name)\n",
    "    PLOT_DIR = \"plots\"\n",
    "\n",
    "    # 2. Load Data & Model\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        print(f\"‚ùå Error: Data file not found.\")\n",
    "        print(f\"   Searched in: {DATA_PATH}\")\n",
    "        print(\"   Please ensure 'eCommerce_Customer_support_data.csv' is in a 'data' folder.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"‚ùå Error: Model file not found.\")\n",
    "        print(f\"   Searched in: {MODEL_PATH}\")\n",
    "        print(\"   Please run 'python main.py' to train the model first.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading data from: {DATA_PATH}\")\n",
    "    df_raw = pd.read_csv(DATA_PATH)\n",
    "    \n",
    "    print(f\"Loading model from: {MODEL_PATH}\")\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "\n",
    "    # 3. Preprocessing (Feature Engineering)\n",
    "    # We initialize the predictor just to access its feature_engineering method\n",
    "    # independent of its internal state\n",
    "    temp_predictor = CSATPredictor(DATA_PATH)\n",
    "    print(\"Applying feature engineering...\")\n",
    "    df_processed = temp_predictor.feature_engineering(df_raw.copy())\n",
    "\n",
    "    # Drop rows where target is missing (same as training)\n",
    "    df_processed = df_processed.dropna(subset=['CSAT Score'])\n",
    "\n",
    "    X = df_processed\n",
    "    y = df_processed['CSAT Score']\n",
    "\n",
    "    # 4. Split Data\n",
    "    # MUST use the same random_state as training to ensure the 'test' set is actually unseen\n",
    "    print(\"Splitting data (Test Size: 20%)...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 5. Generate Predictions\n",
    "    print(\"Predicting on test set...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 6. Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nüèÜ Model Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    print(\"\\nüìù Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # 7. Confusion Matrix\n",
    "    print(\"Generating Confusion Matrix...\")\n",
    "    if not os.path.exists(PLOT_DIR):\n",
    "        os.makedirs(PLOT_DIR)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted CSAT Score')\n",
    "    plt.ylabel('Actual CSAT Score')\n",
    "    plt.title('Confusion Matrix: Actual vs Predicted')\n",
    "    \n",
    "    save_path = os.path.join(PLOT_DIR, \"confusion_matrix.png\")\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"‚úî Confusion Matrix saved to '{save_path}'\")\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
